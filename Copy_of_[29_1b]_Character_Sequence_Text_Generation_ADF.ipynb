{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of [29 1b] Character Sequence Text Generation - ADF",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/retuyu88/digitalentkominfo/blob/master/Copy_of_%5B29_1b%5D_Character_Sequence_Text_Generation_ADF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfwbLGN0zdro",
        "colab_type": "text"
      },
      "source": [
        "<img src = \"https://i.imgur.com/UjutVJd.jpg\" align = \"center\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJBqsX-Uuyq5",
        "colab_type": "text"
      },
      "source": [
        "# Character Level Text Generation\n",
        "\n",
        "Di sini kita akan membuat language model untuk membangkitkan text dari level karakter berdasarkan input sekuens karakter yang diberikan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERD4CSQS43bS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "from tensorflow.keras.utils import get_file\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nJDSNEbi5KaX"
      },
      "source": [
        "# Text Data\n",
        "Untuk memulainya, kita perlu memiliki data untuk melatih model kita. Anda dapat menggunakan file teks apa pun yang Anda inginkan untuk proses ini\n",
        "\n",
        "di sini telah disediakan beberapa data text yang bisa digunakan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkhyOwmn8LtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = {\n",
        "    'shakespeare'  : 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt',\n",
        "    'wonderland'   : 'https://www.gutenberg.org/cache/epub/11/pg11.txt',\n",
        "    'harry'        : 'https://www.linguistik.uzh.ch/dam/jcr:169bff5c-ac13-457b-9acb-4fe7f1ad5cb0/Harry%20Potter%20and%20the%20Sorcerer.txt',\n",
        "    'nietzsche'    : 'https://s3.amazonaws.com/text-datasets/nietzsche.txt',\n",
        "    'frankenstein' : 'https://www.gutenberg.org/files/84/84-0.txt'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2hN0SFj5NRR",
        "colab_type": "text"
      },
      "source": [
        "Pilih satu data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OR-p4_t65EiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = dataset['frankenstein']\n",
        "path = get_file( filename.split('/')[-1], origin=filename)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z5TbFV1z-cN9",
        "colab_type": "text"
      },
      "source": [
        "Kita akan ubah menjadi huruf lowercase agar kita tidak perlu khawatir tentang kapitalisasi dalam contoh ini."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzM2LVWs5RW8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "33c1d32b-9595-4a24-e0bc-1b0864e3156f"
      },
      "source": [
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "\n",
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "corpus length: 440748\n",
            "ï»¿\n",
            "project gutenberg's frankenstein, by mary wollstonecraft (godwin) shelley\n",
            "\n",
            "this ebook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever.  you may copy it, give it away or\n",
            "re-use it under the terms of the projec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gfsGbEFn5R6k"
      },
      "source": [
        "# Encoding\n",
        "Jaringan saraf bekerja dengan angka, bukan karakter teks. Jadi kita perlu mengkonversi input karakter menjadi angka. \n",
        "\n",
        "Pertama, kita urutkan daftar unik semua karakter yang muncul dalam teks tersebut, kemudian gunakan fungsi enumerasi untuk mendapatkan angka yang mewakili karakter tersebut. \n",
        "\n",
        "Berikutnya buat kamus yang menyimpan kunci dan nilai, atau karakter dan angka yang mewakili mereka."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5GYYNc5RT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07cf5fa8-238e-4574-fa7c-4dd187ae6053"
      },
      "source": [
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total chars: 69\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co-Dcee-_NFE",
        "colab_type": "text"
      },
      "source": [
        "# Sequence Building\n",
        "\n",
        "Di sini kita set bahwa maksimum sequence dari karakter input adalah 40\n",
        "\n",
        "Untuk itu, kita harus memotong semua text dalam bentuk sekuens semi-redundan sepanjang 40 karakter. Kita gunakan nilai redundansi sebesar 3 karakter\n",
        "\n",
        "artinya, misal kita memiliki teks: `\"saya suka makan nasi\"`, kemudian kita buat sekuens semi-redundan dengan panjang 5 dan redundansi 2, maka kita akan memiliki\n",
        "* `'saya '` dengan target `'aya s'`\n",
        "* `'ya su'` dengan target `'a suk'`\n",
        "* `' suka'` dengan target `'suka '`\n",
        "* `'uka m'` dengan target `'ka ma'`\n",
        "* dan seterusnya\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdiBnZdC5RRS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb52bf77-7c6e-45c2-e122-8068a5fe99da"
      },
      "source": [
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i+1 : i + maxlen+1])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nb sequences: 146903\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtN3FRiwAPeF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b0c2ef17-df1c-4e42-a4a5-675e45a37bff"
      },
      "source": [
        "for i in range(10):\n",
        "  print([sentences[i]],[next_chars[i]])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"\\ufeff\\nproject gutenberg's frankenstein, by m\"] [\"\\nproject gutenberg's frankenstein, by ma\"]\n",
            "[\"roject gutenberg's frankenstein, by mary\"] [\"oject gutenberg's frankenstein, by mary \"]\n",
            "[\"ect gutenberg's frankenstein, by mary wo\"] [\"ct gutenberg's frankenstein, by mary wol\"]\n",
            "[\" gutenberg's frankenstein, by mary wolls\"] [\"gutenberg's frankenstein, by mary wollst\"]\n",
            "[\"tenberg's frankenstein, by mary wollston\"] [\"enberg's frankenstein, by mary wollstone\"]\n",
            "[\"berg's frankenstein, by mary wollstonecr\"] [\"erg's frankenstein, by mary wollstonecra\"]\n",
            "[\"g's frankenstein, by mary wollstonecraft\"] [\"'s frankenstein, by mary wollstonecraft \"]\n",
            "[' frankenstein, by mary wollstonecraft (g'] ['frankenstein, by mary wollstonecraft (go']\n",
            "['ankenstein, by mary wollstonecraft (godw'] ['nkenstein, by mary wollstonecraft (godwi']\n",
            "['enstein, by mary wollstonecraft (godwin)'] ['nstein, by mary wollstonecraft (godwin) ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PjNCXnQAhMo",
        "colab_type": "text"
      },
      "source": [
        "Berikutnya kita buat data latih dan targetnya berupa vektor angka yang diambil dari dictionary berdasarkan kalimat sekuens yang sudah kita buat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Lw2Tg4253El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "        \n",
        "\n",
        "for i, sentence in enumerate(next_chars):\n",
        "    for t, char in enumerate(sentence):\n",
        "        y[i, t, char_indices[char]] = 1\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9d-oAr5A9yf",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Model\n",
        "Sekarang kita coba bangun jaringan sederhana mengguankan 1 layer LSTM dengan ukuran output vektor 128. Setelah layer LSTM, kita tambahkan Layer Dense untuk memprediksi kelanjutan karakter dari 40 karakter input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhIbD-8j53Bt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "25d1305b-f0ef-48cc-e63c-47db009e346d"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(maxlen, len(chars)), return_sequences=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(chars), activation='softmax')))\n",
        "model.add(Reshape((maxlen, len(chars))))\n",
        "\n",
        "\n",
        "optimizer = Adam(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 03:33:15.063859 139969991964544 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYwLLUM5CPAm",
        "colab_type": "text"
      },
      "source": [
        "# Sample Probability Function\n",
        "Berikut adalah helper function untuk melakukan sampling karakter output berdasarkan output probability dari softmax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VKGcWRB52_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaKAd0M0CbAj",
        "colab_type": "text"
      },
      "source": [
        "# Training Checkpoint\n",
        "Berikutnya mari kita tambahkan sebuah callback pada fungsi training agar kita bisa melihat contoh hasil pembangkitan text yang dilakukan setiap 5 epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rijJvqiB567O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "  if epoch%5==0:\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print('\\n---------------------------------------------------------------------')\n",
        "    print('>>>>> Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    diversity = 0.7\n",
        "    print('\\n>>>>> diversity:', diversity)\n",
        "\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    print('>>>>> Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "\n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds[-1], diversity)\n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        generated += next_char\n",
        "        sentence = sentence[1:] + next_char\n",
        "\n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print('\\n---------------------------------------------------------------------')\n",
        "    print('>>>>> Continuing training')\n",
        "        \n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgscM3uqCklR",
        "colab_type": "text"
      },
      "source": [
        "# Training Process\n",
        "\n",
        "Sekarang tinggal kita latih model Text Generator kita"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7zmN1YM564m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2d31da83-3bf9-4ed1-be7a-af4eb0e00123"
      },
      "source": [
        "model.fit(x, y,\n",
        "          batch_size=1080,\n",
        "          epochs=20,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "146880/146903 [============================>.] - ETA: 0s - loss: 0.8425\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Generating text after Epoch: 0\n",
            "\n",
            ">>>>> diversity: 0.7\n",
            ">>>>> Generating with seed: \"he quitted italy with an attendant, a na\"\n",
            "he quitted italy with an attendant, a native country and sense of my parents were all, when he began to ribernal of women, when all was little in the consummation of my friend and delighted; but i will not credit it.â\n",
            "\n",
            "âsepted on the great and spirit with refugent and labourâi was, in beautience i had contented my mind and then clervancing in a difted how to me.  agatha listened to the heaven to the heavens; i found that i could not\n",
            "mag\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Continuing training\n",
            "146903/146903 [==============================] - 47s 322us/sample - loss: 0.8425\n",
            "Epoch 2/20\n",
            "146903/146903 [==============================] - 28s 187us/sample - loss: 0.8533\n",
            "Epoch 3/20\n",
            "146903/146903 [==============================] - 28s 194us/sample - loss: 0.8481\n",
            "Epoch 4/20\n",
            "146903/146903 [==============================] - 29s 198us/sample - loss: 0.8365\n",
            "Epoch 5/20\n",
            "146903/146903 [==============================] - 28s 193us/sample - loss: 0.8253\n",
            "Epoch 6/20\n",
            "146880/146903 [============================>.] - ETA: 0s - loss: 0.8059\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Generating text after Epoch: 5\n",
            "\n",
            ">>>>> diversity: 0.7\n",
            ">>>>> Generating with seed: \"in the woods.\n",
            "\n",
            "âand now, with the world \"\n",
            "in the woods.\n",
            "\n",
            "âand now, with the world to\n",
            "remove and whose village with a fain in writing without furtherd.\n",
            "\n",
            "âthese were always hate the murderer i have myself acted, and the cubind benevolest clamp her happiness which he can discribe.  i will not think that i improved in the\n",
            "circumstantically in the meantime, fears. the insail it in every benefit us.  âthe instrument of which it was not only in the light of a never-england. it is the \n",
            "---------------------------------------------------------------------\n",
            ">>>>> Continuing training\n",
            "146903/146903 [==============================] - 74s 501us/sample - loss: 0.8059\n",
            "Epoch 7/20\n",
            "146903/146903 [==============================] - 40s 269us/sample - loss: 0.8117\n",
            "Epoch 8/20\n",
            "146903/146903 [==============================] - 39s 267us/sample - loss: 0.7953\n",
            "Epoch 9/20\n",
            "146903/146903 [==============================] - 39s 267us/sample - loss: 0.7868\n",
            "Epoch 10/20\n",
            "146903/146903 [==============================] - 39s 266us/sample - loss: 0.7834\n",
            "Epoch 11/20\n",
            "146880/146903 [============================>.] - ETA: 0s - loss: 0.7746\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Generating text after Epoch: 10\n",
            "\n",
            ">>>>> diversity: 0.7\n",
            ">>>>> Generating with seed: \"ed that change of scene and varied amuse\"\n",
            "ed that change of scene and varied amusement of a murderer of its extreme glittering witnesses are blind bared trusemly, and at that moment, a science of the bore amiam\n",
            "had rain bitdly envelop, with strength; he is very tall upon me as i\n",
            "congraved in\n",
            "the completion of the information the compogrance of the copyright status the\n",
            "moon, as if i found that i desired to me happy, whilst you do not suppose,\n",
            "eing in\n",
            "heir into it licers?  i reme\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Continuing training\n",
            "146903/146903 [==============================] - 76s 521us/sample - loss: 0.7746\n",
            "Epoch 12/20\n",
            "146903/146903 [==============================] - 38s 260us/sample - loss: 0.7614\n",
            "Epoch 13/20\n",
            "146903/146903 [==============================] - 38s 261us/sample - loss: 0.7507\n",
            "Epoch 14/20\n",
            "146903/146903 [==============================] - 39s 263us/sample - loss: 0.7501\n",
            "Epoch 15/20\n",
            "146903/146903 [==============================] - 38s 261us/sample - loss: 0.7369\n",
            "Epoch 16/20\n",
            "146880/146903 [============================>.] - ETA: 0s - loss: 0.7364\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Generating text after Epoch: 15\n",
            "\n",
            ">>>>> diversity: 0.7\n",
            ">>>>> Generating with seed: \"gage with a solemn\n",
            "promise that if the v\"\n",
            "gage with a solemn\n",
            "promise that if the vallors\n",
            "and wondrous scents was the modesty, and\n",
            "my spirits who assistly been silent, because it was full of imagination for his attacks, a sceneryment which i had seen my angel of the believe his attributed my enemy head of never, i shuttered in\n",
            "eldeng\n",
            "appears to leave their history, and i continued to record. the sexcipi\n",
            "and wisdom; he bless me this agreement, the path,\n",
            "which the being neither so\n",
            "---------------------------------------------------------------------\n",
            ">>>>> Continuing training\n",
            "146903/146903 [==============================] - 77s 522us/sample - loss: 0.7364\n",
            "Epoch 17/20\n",
            "146903/146903 [==============================] - 38s 260us/sample - loss: 0.7324\n",
            "Epoch 18/20\n",
            "146903/146903 [==============================] - 38s 262us/sample - loss: 0.7298\n",
            "Epoch 19/20\n",
            "146903/146903 [==============================] - 38s 260us/sample - loss: 0.7201\n",
            "Epoch 20/20\n",
            "146903/146903 [==============================] - 38s 256us/sample - loss: 0.7119\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f4cf0a6aa58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD2PM4OLvku8",
        "colab_type": "text"
      },
      "source": [
        "# Testing Process\n",
        "setelah model terlatih, mari kita uji untuk membangkitkan text sepanjang 400 karakter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lII3wCV65611",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e7054e18-9c59-46b5-ca26-0a9c81659f1e"
      },
      "source": [
        "start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "diversity = 0.7\n",
        "print('\\n>>>>> diversity:', diversity)\n",
        "\n",
        "generated = ''\n",
        "sentence = text[start_index: start_index + maxlen]\n",
        "generated += sentence\n",
        "print('>>>>> Generating with seed: \"' + sentence + '\"')\n",
        "sys.stdout.write(generated)\n",
        "\n",
        "for i in range(400):\n",
        "    x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "    for t, char in enumerate(sentence):\n",
        "        x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    preds = model.predict(x_pred, verbose=0)[0]\n",
        "    next_index = sample(preds[-1], diversity)\n",
        "    next_char = indices_char[next_index]\n",
        "\n",
        "    generated += next_char\n",
        "    sentence = sentence[1:] + next_char\n",
        "\n",
        "    sys.stdout.write(next_char)\n",
        "    sys.stdout.flush()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            ">>>>> diversity: 0.7\n",
            ">>>>> Generating with seed: \"raw near, he aimed a gun,\n",
            "which he carri\"\n",
            "raw near, he aimed a gun,\n",
            "which he carried wathful, for it was to be restless.  in darkness; but they were clouded my intended to the heavens; and yet you are the stranger repented all was dry; all sleep.\n",
            "\n",
            "âit was allied to this genius and uried see presented\n",
            "in his\n",
            "family!  precious to a coin, i found my own spirit to the sun was opened and destroy the place in the same time than the cause of her dearest conviction that i could not ref"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB_ojCQ6zmKS",
        "colab_type": "text"
      },
      "source": [
        "<p>Copyright &copy; 2019 <a href=https://www.linkedin.com/in/andityaarifianto/>ADF</a> </p>"
      ]
    }
  ]
}